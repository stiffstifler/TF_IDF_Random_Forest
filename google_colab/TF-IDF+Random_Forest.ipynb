{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvqnlJIofEO/y+ddkLoDBT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Task: Classifying textual data using a multi-label approach.\n","\n","Stack: TF-IDF, Random Forest\n","\n","Steps:\n","1. Data loading and normalization\n","2. label binarization and title vectorization\n","3. Splitting the data into training and test parts, according to 80/20 standard.\n","4. Model training\n","5. Model evaluation and results\n","\n","Result: Achieved an accuracy of 89%, which is 9% higher than the results obtained in the Logistic Regression model.\n","\n","Difficulties:\n","- Owner label is equal to 0\n","- Insufficient handling of rare classes\n","\n","Solutions undertaken:\n","- Used NLTK for high quality noise cleanup\n","- Added lematization\n","- Testing different variants of parameters n_estimators, test_size.\n","\n","Opportunities for optimization:\n","- Balancing classes to increase focus on rare metrics like Owner.\n","- Changing vectorization tool (e.g. Word2Vec)\n","- Changing the model (e.g. MLN, BERT)"],"metadata":{"id":"4OEYjVkqOc_p"}},{"cell_type":"code","source":["My results:\n","\n","Classification Report:\n","                              precision    recall  f1-score   support\n","\n","               Chief Officer       0.96      0.60      0.74        40\n","                    Director       0.93      0.93      0.93        97\n","Individual Contributor/Staff       0.97      0.98      0.97       226\n","                     Manager       0.85      0.53      0.65        32\n","                       Owner       0.00      0.00      0.00         2\n","              Vice President       0.93      0.93      0.93        67\n","\n","                   micro avg       0.95      0.89      0.92       464\n","                   macro avg       0.77      0.66      0.70       464\n","                weighted avg       0.94      0.89      0.91       464\n","                 samples avg       0.92      0.91      0.91       464\n","\n","Total model accuracy:\n","0.8928571428571429"],"metadata":{"id":"TOjE8_G7PaAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pv9EQVOWz8sr","executionInfo":{"status":"ok","timestamp":1736932473614,"user_tz":-60,"elapsed":4275,"user":{"displayName":"Stiff Stifler","userId":"02148404630227853373"}},"outputId":"264d747d-6d5c-48ee-be27-c1dcbb5d29bc"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Classification Report:\n","                              precision    recall  f1-score   support\n","\n","               Chief Officer       0.96      0.60      0.74        40\n","                    Director       0.93      0.93      0.93        97\n","Individual Contributor/Staff       0.97      0.98      0.97       226\n","                     Manager       0.85      0.53      0.65        32\n","                       Owner       0.00      0.00      0.00         2\n","              Vice President       0.93      0.93      0.93        67\n","\n","                   micro avg       0.95      0.89      0.92       464\n","                   macro avg       0.77      0.66      0.70       464\n","                weighted avg       0.94      0.89      0.91       464\n","                 samples avg       0.92      0.91      0.91       464\n","\n","Total model accuracy:\n","0.8928571428571429\n"]}],"source":["from google.colab import drive\n","import nltk\n","import pandas as pandas\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","\n","# NLTK Resources\n","nltk.download(\"stopwords\")\n","nltk.download(\"punkt\")\n","nltk.download(\"wordnet\")\n","nltk.download(\"punkt_tab\")\n","\n","\n","# 1. Data pre-processing\n","\n","# Downloading dataset from Google Drive\n","drive.mount(\"/content/drive\")\n","data_path = \"/content/drive/My Drive/dataset_path/dataset_name.xlsx\"\n","\n","data = pandas.read_excel(data_path)\n","\n","data.fillna(\"\", inplace=True) # Replacing NaN > empty string\n","\n","# Labels processing\n","data[\"Combined_Labels\"] = data[[\"Column 1\", \"Column 2\", \"Column 3\", \"Column 4\"]].values.tolist() # Split the labels\n","data[\"Combined_Labels\"] = data[\"Combined_Labels\"].apply(lambda x: list(filter(None, x)))  # Remove empty values\n","\n","def text_cleaner(text):\n","    text = text.lower() # Register\n","    tokens = nltk.word_tokenize(text) # Tokenization\n","    stop_words = set(stopwords.words(\"english\")) # Noise with NLTK\n","\n","    filtered_tokens = []\n","    for word in tokens:\n","        if word not in stop_words:\n","            filtered_tokens.append(word)\n","    tokens = filtered_tokens\n","\n","    # Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_tokens = []\n","    for word in tokens:\n","        lemmatized_word = lemmatizer.lemmatize(word)\n","        lemmatized_tokens.append(lemmatized_word)\n","    tokens = lemmatized_tokens\n","\n","    return \" \".join(tokens)\n","\n","# Title processing\n","data[\"Processed_Title\"] = data[\"Title\"].apply(text_cleaner)\n","\n","# attributes X abd labels Y\n","X_titles = data[\"Processed_Title\"]\n","Y_labels = data[\"Combined_Labels\"]\n","\n","# Labels to binary\n","binar = MultiLabelBinarizer()\n","y_binarized = binar.fit_transform(Y_labels)\n","\n","\n","# 2. TF-IDF vectorization\n","vector = TfidfVectorizer()\n","X_tfidf = vector.fit_transform(X_titles)\n","\n","\n","# 3. 80/20 data split\n","X_train, X_test, Y_train, Y_test = train_test_split(X_tfidf, y_binarized, test_size=0.20, random_state=1)\n","\n","\n","# 4. Training\n","model = RandomForestClassifier(random_state=1, n_estimators=100)\n","model.fit(X_train, Y_train)\n","\n","# 5. Result\n","Y_pred = model.predict(X_test)\n","\n","results = classification_report(Y_test, Y_pred, target_names=binar.classes_, zero_division=0)\n","accuracy = accuracy_score(Y_test, Y_pred)\n","\n","# Print metrics\n","print(f\"Classification Report:\\n{results}\")\n","print(f\"Total model accuracy:\\n{accuracy}\")"]}]}